{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7b70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aae25a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: OpenAI in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (4.10.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (4.66.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (2.6.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (4.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from OpenAI) (1.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->OpenAI) (2.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->OpenAI) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->OpenAI) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from tqdm>4->OpenAI) (0.4.4)\n",
      "Requirement already satisfied: llama-index-core in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (0.10.22)\n",
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (0.1.12)\n",
      "Requirement already satisfied: llama-index-embeddings-openai in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (3.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (3.9.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\nikhi\\appdata\\roaming\\python\\python38\\site-packages (from llama-index-core) (10.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (0.1.13)\n",
      "Requirement already satisfied: httpx in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (0.27.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (2024.3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (2.0.28)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (2.0.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nikhi\\appdata\\roaming\\python\\python38\\site-packages (from llama-index-core) (1.24.4)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (0.6.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (4.10.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (8.2.2)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llama-index-core) (4.66.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core) (1.12.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core) (2.6.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (4.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (1.0.4)\n",
      "Requirement already satisfied: idna in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (2.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpx->llama-index-core) (2023.7.22)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2023.12.25)\n",
      "Requirement already satisfied: click in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from anyio->httpx->llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core) (2.16.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core) (0.4.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core) (3.21.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas->llama-index-core) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nikhi\\anaconda3\\lib\\site-packages (from pandas->llama-index-core) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nikhi\\appdata\\roaming\\python\\python38\\site-packages (from pandas->llama-index-core) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nikhi\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index.core pymysql -q\n",
    "!pip install OpenAI\n",
    "!pip install -U llama-index-core llama-index-llms-openai llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893c5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging Capabilities to see what happens in LlamaIndex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db85214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, force=True)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a235a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0bea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = \"root\"\n",
    "db_password = \"root\"\n",
    "db_host = \"127.0.0.1\"\n",
    "db_name = \"search_engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad476bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.llamaindex.ai/en/v0.10.17/api_reference/struct_store.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c4817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Upscale', 'United Kingdom', 'London', 2011, 'Software, SaaS, E-Commerce', None)\n",
      "('iStarter', 'United Kingdom', 'London', 2012, 'E-Commerce, IT, Healthcare', None)\n",
      "('Huckletree', 'United Kingdom', 'London', 2014, 'E-Commerce, Software, Mobile Apps', None)\n",
      "('Potential VC', 'United Kingdom', 'London', 2015, 'E-Commerce, Apps, Software', None)\n",
      "('ChangeLabs', 'United Kingdom', 'London', 2018, 'Electric Vehicles, Education, E-Commerce', None)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\"\n",
    "\n",
    "# Create an engine instance\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test the connection using raw SQL\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM Details WHERE Region = 'London' AND services LIKE '%E-Commerce%'\"))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e5e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_Info = {\n",
    "    \"organizations\": \"stores company name.\",\n",
    "    \"Country\":\"stores company country location.\",\n",
    "    \"Region\":\"stores company detail region wise.\",\n",
    "    \"services\":\"stores objective of company.\",\n",
    "    \"Founding\":\"stores company founding Year.\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e97b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.utilities.sql_wrapper.SQLDatabase at 0x1fda53eb910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "tables = [\"Socialorganizations\",\"Country\",\"Region\",\"services\",\"Founding\"]\n",
    "#sql_database = SQLDatabase(engine, include_tables=tables,sample_rows_in_table_info=4)\n",
    "sql_database = SQLDatabase(engine, sample_rows_in_table_info=5)\n",
    "sql_database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db3bdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['details']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sql_database._all_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0881ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3457e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from llama_index.core.callbacks import CallbackManager, TokenCountingHandler\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    ")\n",
    "\n",
    "callback_manager = CallbackManager([token_counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321d86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0a754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d634df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_24172\\1792144215.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "  llm=llm,callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e508c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae503ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'details' has columns: organization (VARCHAR(255)), country (VARCHAR(255)), Region (VARCHAR(255)), founding_year (INTEGER), services (VARCHAR(255)), industry (VARCHAR(255)), and foreign keys: .\n",
      "> Table desc str: Table 'details' has columns: organization (VARCHAR(255)), country (VARCHAR(255)), Region (VARCHAR(255)), founding_year (INTEGER), services (VARCHAR(255)), industry (VARCHAR(255)), and foreign keys: .\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_str = \"startups based in London?\"\n",
    "# query_str =\"What are the most frequently mentioned keywords or phrases in the comments made by sales representatives\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d14ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the startups based in London include ChangeLabs, Revolut, Data Pitch, Insurtech Gateway, and DigitalHealth.London, among others. These startups were founded in recent years, with founding years ranging from 2018 to 2001. London has a vibrant startup ecosystem with a variety of innovative companies across different industries.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0f30c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT organization, country, founding_year\n",
      "FROM details\n",
      "WHERE Region = 'London'\n",
      "ORDER BY founding_year DESC;\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata['sql_query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aab0e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ChangeLabs', 'United Kingdom', 2018), ('Revolut', 'United Kingdom', 2018), ('Data Pitch', 'United Kingdom', 2017), ('Insurtech Gateway', 'United Kingdom', 2016), ('DigitalHealth.London', 'United Kingdom', 2016), ('Founders Factory', 'United Kingdom', 2015), ('Pi Ventures', 'United Kingdom', 2015), ('CyLon', 'United Kingdom', 2015), ('Startup Campus', 'United Kingdom', 2015), ('Potential VC', 'United Kingdom', 2015), ('London Co-Investment Fund', 'United Kingdom', 2014), ('Outlier Ventures', 'United Kingdom', 2014), ('Chivas Ventures', 'United Kingdom', 2014), ('Breed Reply', 'United Kingdom', 2014), ('Huckletree', 'United Kingdom', 2014), ('Bethnal Green Ventures', 'United Kingdom', 2012), ('Collider', 'United Kingdom', 2012), ('iStarter', 'United Kingdom', 2012), ('L Marks', 'United Kingdom', 2012), ('Entrepreneur First', 'United Kingdom', 2011), ('Upscale', 'United Kingdom', 2011), ('Startupbootcamp', 'United Kingdom', 2010), ('Pario Ventures', 'United Kingdom', 2010), ('Tech Nation', 'United Kingdom', 2010), ('Geovation', 'United Kingdom', 2009), ('Techstars London', 'United Kingdom', 2006), ('Carbon Trust', 'United Kingdom', 2001)]\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe15c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n"
     ]
    }
   ],
   "source": [
    "print(token_counter.total_llm_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356a2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter.reset_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07bd3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.objects import ObjectIndex\n",
    "from llama_index.core.objects import SQLTableNodeMapping, SQLTableSchema\n",
    "import pandas as pd\n",
    "\n",
    "tables = list(sql_database._all_tables)\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = []\n",
    "for table in tables:\n",
    "    table_schema_objs.append((SQLTableSchema(table_name = table, context_str =table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "429e9ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7e11866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'details' has columns: organization (VARCHAR(255)), country (VARCHAR(255)), Region (VARCHAR(255)), founding_year (INTEGER), services (VARCHAR(255)), industry (VARCHAR(255)), and foreign keys: . The table description is: details\n",
      "> Table desc str: Table 'details' has columns: organization (VARCHAR(255)), country (VARCHAR(255)), Region (VARCHAR(255)), founding_year (INTEGER), services (VARCHAR(255)), industry (VARCHAR(255)), and foreign keys: . The table description is: details\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=3), service_context=service_context\n",
    ")\n",
    "response = query_engine.query(\"Organization located in united kingdom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f84645e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of organizations located in the United Kingdom: Bethnal Green Ventures, Breed Reply, Carbon Trust, ChangeLabs, Chivas Ventures, CodeBase, Collider, CyLon, Data Pitch, DigitalHealth.London, Entrepreneur First, Founders Factory, Geovation, Huckletree, Ignite, Insurtech Gateway, iStarter, L Marks, London Co-Investment Fund, Outlier Ventures, Oxygen Accelerator, Pario Ventures, Pi Ventures, Potential VC, Revolut, Startup Campus, Startupbootcamp, Tech Nation, Techstars London, and Upscale.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75105bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749\n"
     ]
    }
   ],
   "source": [
    "print(token_counter.total_llm_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00135b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
